{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Real Time Pothole Detection using SSD",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aidenjcheng/football-ai/blob/main/mmmmm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "andrewmvd_pothole_detection_path = kagglehub.dataset_download('andrewmvd/pothole-detection')\n",
        "sudhanshu2198_potholes_detection_inference_on_videos_path = kagglehub.dataset_download('sudhanshu2198/potholes-detection-inference-on-videos')\n",
        "sudhanshu2198_pothole_detection_learned_weights_path = kagglehub.dataset_download('sudhanshu2198/pothole-detection-learned-weights')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ws5DK7hlzBo3",
        "outputId": "521a4939-a12e-4b90-c050-047f99ca5c7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'pothole-detection' dataset.\n",
            "Using Colab cache for faster access to the 'potholes-detection-inference-on-videos' dataset.\n",
            "Using Colab cache for faster access to the 'pothole-detection-learned-weights' dataset.\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "-TLiLaSwzBo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycocotools\n",
        "! pip install -U ffmpeg"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-09-01T05:18:33.774134Z",
          "iopub.execute_input": "2023-09-01T05:18:33.774728Z",
          "iopub.status.idle": "2023-09-01T05:18:58.968779Z",
          "shell.execute_reply.started": "2023-09-01T05:18:33.774681Z",
          "shell.execute_reply": "2023-09-01T05:18:58.967504Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "X376L3h_zBo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader,Subset\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.models.detection.ssd import SSDHead,det_utils\n",
        "from torchvision.models.detection import ssd300_vgg16,SSD300_VGG16_Weights\n",
        "import torchvision.transforms.functional as tf\n",
        "import albumentations as A\n",
        "import pycocotools\n",
        "import torchmetrics\n",
        "from torchmetrics.detection import MeanAveragePrecision"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-09-01T05:18:58.973384Z",
          "iopub.execute_input": "2023-09-01T05:18:58.97374Z",
          "iopub.status.idle": "2023-09-01T05:18:58.982168Z",
          "shell.execute_reply.started": "2023-09-01T05:18:58.973708Z",
          "shell.execute_reply": "2023-09-01T05:18:58.981176Z"
        },
        "trusted": true,
        "id": "H8Bo2s1WzBo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:18:58.983618Z",
          "iopub.execute_input": "2023-09-01T05:18:58.984211Z",
          "iopub.status.idle": "2023-09-01T05:18:59.001417Z",
          "shell.execute_reply.started": "2023-09-01T05:18:58.984175Z",
          "shell.execute_reply": "2023-09-01T05:18:59.000467Z"
        },
        "trusted": true,
        "id": "KII-yom_zBo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "DVv9GOFBzBo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir=\"/kaggle/input/pothole-detection/images\"\n",
        "annot_dir=\"/kaggle/input/pothole-detection/annotations\"\n",
        "\n",
        "#label 0 is fixed for background\n",
        "classes=[\"background\",\"pothole\"]\n",
        "\n",
        "num_classes=2\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size=4\n",
        "epochs=40\n",
        "learning_rate=3e-5\n",
        "\n",
        "model_weights_file=\"model.pth\"\n",
        "\n",
        "threshold=0.25\n",
        "iou_threshold=0.75"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:08.252972Z",
          "iopub.execute_input": "2023-09-01T05:19:08.253374Z",
          "iopub.status.idle": "2023-09-01T05:19:08.25976Z",
          "shell.execute_reply.started": "2023-09-01T05:19:08.253329Z",
          "shell.execute_reply": "2023-09-01T05:19:08.258673Z"
        },
        "trusted": true,
        "id": "bXigSrlvzBo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bounding Box Data Analysis"
      ],
      "metadata": {
        "id": "PKSvzWzRzBo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_xml(annot_path):\n",
        "    tree=ET.parse(annot_path)\n",
        "    root=tree.getroot()\n",
        "\n",
        "    width=int(root.find(\"size\").find(\"width\").text)\n",
        "    height=int(root.find(\"size\").find(\"height\").text)\n",
        "    boxes=[]\n",
        "\n",
        "    for obj in root.findall(\"object\"):\n",
        "        bbox=obj.find(\"bndbox\")\n",
        "        xmin=int(bbox.find(\"xmin\").text)\n",
        "        ymin=int(bbox.find(\"ymin\").text)\n",
        "        xmax=int(bbox.find(\"xmax\").text)\n",
        "        ymax=int(bbox.find(\"ymax\").text)\n",
        "\n",
        "        boxes.append([xmin,ymin,xmax,ymax])\n",
        "\n",
        "    return boxes,height,width"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:08.9029Z",
          "iopub.execute_input": "2023-09-01T05:19:08.90327Z",
          "iopub.status.idle": "2023-09-01T05:19:08.910417Z",
          "shell.execute_reply.started": "2023-09-01T05:19:08.903239Z",
          "shell.execute_reply": "2023-09-01T05:19:08.909516Z"
        },
        "trusted": true,
        "id": "wJD1bQvJzBo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_img=[]\n",
        "for annot_name in os.listdir(annot_dir):\n",
        "    img_name=annot_name[:-4]+\".png\"\n",
        "    annot_path=os.path.join(annot_dir,annot_name)\n",
        "    boxes,height,width=parse_xml(annot_path)\n",
        "\n",
        "    for box in boxes:\n",
        "        if box[0]<0 or box[0]>=box[2] or box[2]>width:\n",
        "            print(box[0],box[2],width)\n",
        "            print(\"x\",annot_name)\n",
        "            print(\"*\"*50)\n",
        "            ignore_img.append(img_name)\n",
        "        elif box[1]<0 or box[1]>=box[3] or box[3]>height:\n",
        "            print(box[1],box[3],height)\n",
        "            print(\"y\",file_name)\n",
        "            print(\"*\"*50)\n",
        "            ignore_img.append(img_name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:09.282493Z",
          "iopub.execute_input": "2023-09-01T05:19:09.283176Z",
          "iopub.status.idle": "2023-09-01T05:19:09.786093Z",
          "shell.execute_reply.started": "2023-09-01T05:19:09.283139Z",
          "shell.execute_reply": "2023-09-01T05:19:09.785109Z"
        },
        "trusted": true,
        "id": "Ny0q7LTxzBo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:09.788388Z",
          "iopub.execute_input": "2023-09-01T05:19:09.788833Z",
          "iopub.status.idle": "2023-09-01T05:19:09.795089Z",
          "shell.execute_reply.started": "2023-09-01T05:19:09.788793Z",
          "shell.execute_reply": "2023-09-01T05:19:09.794144Z"
        },
        "trusted": true,
        "id": "WFeADOJPzBo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "qBfGBdzZzBo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform=A.Compose([A.HorizontalFlip(),\n",
        "                           A.ShiftScaleRotate(rotate_limit=15,value=0,\n",
        "                                              border_mode=cv2.BORDER_CONSTANT),\n",
        "\n",
        "                           A.OneOf(\n",
        "                                   [A.CLAHE(),\n",
        "                                    A.RandomBrightnessContrast(),\n",
        "                                    A.HueSaturationValue()],p=1),\n",
        "                           A.GaussNoise(),\n",
        "                           A.RandomResizedCrop(height=480,width=480)],\n",
        "                          bbox_params=A.BboxParams(format=\"pascal_voc\",min_visibility=0.15,\n",
        "                                                   label_fields=[\"labels\"]))\n",
        "\n",
        "val_transform=A.Compose([A.Resize(height=480,width=480)],\n",
        "                        bbox_params=A.BboxParams(format=\"pascal_voc\",min_visibility=0.15,\n",
        "                                                 label_fields=[\"labels\"]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:11.972549Z",
          "iopub.execute_input": "2023-09-01T05:19:11.97325Z",
          "iopub.status.idle": "2023-09-01T05:19:11.98113Z",
          "shell.execute_reply.started": "2023-09-01T05:19:11.973213Z",
          "shell.execute_reply": "2023-09-01T05:19:11.979686Z"
        },
        "trusted": true,
        "id": "SDxY8UGOzBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset"
      ],
      "metadata": {
        "id": "ejVbd7VXzBo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PotholeDetection(Dataset):\n",
        "    def __init__(self,img_dir,annot_dir,transform=None):\n",
        "        super().__init__()\n",
        "        self.img_dir=img_dir\n",
        "        self.annot_dir=annot_dir\n",
        "        self.img_list=sorted([img for img in os.listdir(self.img_dir)\n",
        "                              if img not in ignore_img])\n",
        "        self.transform=transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        img_name=self.img_list[idx]\n",
        "        img_path=os.path.join(self.img_dir,img_name)\n",
        "        img=cv2.imread(img_path)\n",
        "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        annot_name=img_name[:-4]+\".xml\"\n",
        "        annot_path=os.path.join(self.annot_dir,annot_name)\n",
        "        boxes,height,width=parse_xml(annot_path)\n",
        "        labels=[1]*len(boxes)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            transformed=self.transform(image=img,bboxes=boxes,labels=labels)\n",
        "            img=transformed[\"image\"]\n",
        "            boxes=transformed[\"bboxes\"]\n",
        "            labels=transformed[\"labels\"]\n",
        "\n",
        "        if len(np.array(boxes).shape)!=2 or np.array(boxes).shape[-1]!=4:\n",
        "            boxes=[[0.0,0.0,1.0,1.0]]\n",
        "            labels=[0]\n",
        "\n",
        "        img=img/255\n",
        "        img=tf.to_tensor(img)\n",
        "        img=img.to(dtype=torch.float32)\n",
        "        target={}\n",
        "        target[\"boxes\"]=torch.tensor(boxes,dtype=torch.float32)\n",
        "        target[\"labels\"]=torch.tensor(labels,dtype=torch.int64)\n",
        "        target[\"id\"]=torch.tensor(idx)\n",
        "\n",
        "        return img,target"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:12.54268Z",
          "iopub.execute_input": "2023-09-01T05:19:12.543057Z",
          "iopub.status.idle": "2023-09-01T05:19:12.555456Z",
          "shell.execute_reply.started": "2023-09-01T05:19:12.543025Z",
          "shell.execute_reply": "2023-09-01T05:19:12.554497Z"
        },
        "trusted": true,
        "id": "gHaDULxWzBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=PotholeDetection(img_dir,annot_dir,train_transform)\n",
        "val_ds=PotholeDetection(img_dir,annot_dir,val_transform)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:12.877327Z",
          "iopub.execute_input": "2023-09-01T05:19:12.878419Z",
          "iopub.status.idle": "2023-09-01T05:19:12.885715Z",
          "shell.execute_reply.started": "2023-09-01T05:19:12.878375Z",
          "shell.execute_reply": "2023-09-01T05:19:12.88464Z"
        },
        "trusted": true,
        "id": "24Zll2QqzBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:13.127475Z",
          "iopub.execute_input": "2023-09-01T05:19:13.12842Z",
          "iopub.status.idle": "2023-09-01T05:19:13.133565Z",
          "shell.execute_reply.started": "2023-09-01T05:19:13.128378Z",
          "shell.execute_reply": "2023-09-01T05:19:13.132583Z"
        },
        "trusted": true,
        "id": "xFldK7K1zBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs=list(range(len(train_ds)))\n",
        "\n",
        "np.random.shuffle(idxs)\n",
        "train_idx=idxs[:int(0.85*len(train_ds))]\n",
        "val_idx=idxs[int(0.85*len(train_ds)):]\n",
        "\n",
        "train_ds=Subset(train_ds,train_idx)\n",
        "val_ds=Subset(val_ds,val_idx)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:13.448259Z",
          "iopub.execute_input": "2023-09-01T05:19:13.44896Z",
          "iopub.status.idle": "2023-09-01T05:19:13.455275Z",
          "shell.execute_reply.started": "2023-09-01T05:19:13.448921Z",
          "shell.execute_reply": "2023-09-01T05:19:13.454191Z"
        },
        "trusted": true,
        "id": "M-GNxgItzBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:13.75227Z",
          "iopub.execute_input": "2023-09-01T05:19:13.753747Z",
          "iopub.status.idle": "2023-09-01T05:19:13.764696Z",
          "shell.execute_reply.started": "2023-09-01T05:19:13.753693Z",
          "shell.execute_reply": "2023-09-01T05:19:13.763725Z"
        },
        "trusted": true,
        "id": "EzQKmW1NzBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "5H9xECX0zBo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_bbox(img,target,color=(0,255,0)):\n",
        "    img=np.transpose(img.cpu().numpy(),(1,2,0))\n",
        "    boxes=target[\"boxes\"].cpu().numpy().astype(\"int\")\n",
        "    labels=target[\"labels\"].cpu().numpy()\n",
        "    img=img.copy()\n",
        "    for i,box in enumerate(boxes):\n",
        "        idx=int(labels[i])\n",
        "        text=classes[idx]\n",
        "\n",
        "        cv2.rectangle(img,(box[0],box[1]),(box[2],box[3]),color,2)\n",
        "        y=box[1]-10 if box[1]-10>10 else box[1]+10\n",
        "        cv2.putText(img,text,(box[0],y),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,2)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:15.117304Z",
          "iopub.execute_input": "2023-09-01T05:19:15.118002Z",
          "iopub.status.idle": "2023-09-01T05:19:15.125779Z",
          "shell.execute_reply.started": "2023-09-01T05:19:15.117966Z",
          "shell.execute_reply": "2023-09-01T05:19:15.124796Z"
        },
        "trusted": true,
        "id": "VtovbbBlzBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axes=plt.subplots(4,2,figsize=(12,24))\n",
        "plt.subplots_adjust(wspace=0.1,hspace=0.1)\n",
        "ax=axes.flatten()\n",
        "\n",
        "idxs=np.random.choice(range(len(train_ds)),8)\n",
        "for i,idx in enumerate(idxs):\n",
        "    img,target=train_ds[idx]\n",
        "    output_img=show_bbox(img,target)\n",
        "    ax[i].imshow(output_img)\n",
        "    ax[i].axis(\"off\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:15.377315Z",
          "iopub.execute_input": "2023-09-01T05:19:15.378217Z",
          "iopub.status.idle": "2023-09-01T05:19:17.575673Z",
          "shell.execute_reply.started": "2023-09-01T05:19:15.378178Z",
          "shell.execute_reply": "2023-09-01T05:19:17.568535Z"
        },
        "trusted": true,
        "id": "mFqlW-IIzBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "BTvih_OTzBo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:31.807652Z",
          "iopub.execute_input": "2023-09-01T05:19:31.808024Z",
          "iopub.status.idle": "2023-09-01T05:19:31.813081Z",
          "shell.execute_reply.started": "2023-09-01T05:19:31.807993Z",
          "shell.execute_reply": "2023-09-01T05:19:31.811817Z"
        },
        "trusted": true,
        "id": "GIHOQgmUzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl=DataLoader(train_ds,batch_size=batch_size,shuffle=True,num_workers=os.cpu_count(),\n",
        "                    collate_fn=collate_fn,\n",
        "                    pin_memory=True if device==\"cuda\" else False)\n",
        "val_dl=DataLoader(val_ds,batch_size=batch_size,shuffle=False,num_workers=os.cpu_count(),\n",
        "                  collate_fn=collate_fn,\n",
        "                  pin_memory=True if device==\"cuda\" else False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:32.112809Z",
          "iopub.execute_input": "2023-09-01T05:19:32.113172Z",
          "iopub.status.idle": "2023-09-01T05:19:32.120068Z",
          "shell.execute_reply.started": "2023-09-01T05:19:32.11314Z",
          "shell.execute_reply": "2023-09-01T05:19:32.118583Z"
        },
        "trusted": true,
        "id": "dhAXOIowzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "9RJQBnQBzBo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=ssd300_vgg16(weights=SSD300_VGG16_Weights.DEFAULT)\n",
        "\n",
        "in_channels=det_utils.retrieve_out_channels(model.backbone,(480,480))\n",
        "num_anchors=model.anchor_generator.num_anchors_per_location()\n",
        "model.head=SSDHead(in_channels=in_channels,num_anchors=num_anchors,\n",
        "                   num_classes=num_classes)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:32.778466Z",
          "iopub.execute_input": "2023-09-01T05:19:32.779148Z",
          "iopub.status.idle": "2023-09-01T05:19:52.142329Z",
          "shell.execute_reply.started": "2023-09-01T05:19:32.77911Z",
          "shell.execute_reply": "2023-09-01T05:19:52.141356Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "tWbdyWWbzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in model.backbone.features.parameters():\n",
        "    params.requires_grad=False\n",
        "\n",
        "parameters=[params for params in model.parameters() if params.requires_grad]\n",
        "\n",
        "optimizer=optim.Adam(parameters,lr=learning_rate)\n",
        "lr_scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1,\n",
        "                                                  patience=7, threshold=0.0001)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:52.144205Z",
          "iopub.execute_input": "2023-09-01T05:19:52.145113Z",
          "iopub.status.idle": "2023-09-01T05:19:52.151968Z",
          "shell.execute_reply.started": "2023-09-01T05:19:52.145075Z",
          "shell.execute_reply": "2023-09-01T05:19:52.150876Z"
        },
        "trusted": true,
        "id": "q5THxYJDzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "H3PPU88QzBo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for params in optimizer.param_groups:\n",
        "        return params[\"lr\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:52.153196Z",
          "iopub.execute_input": "2023-09-01T05:19:52.153574Z",
          "iopub.status.idle": "2023-09-01T05:19:52.16346Z",
          "shell.execute_reply.started": "2023-09-01T05:19:52.153542Z",
          "shell.execute_reply": "2023-09-01T05:19:52.162385Z"
        },
        "trusted": true,
        "id": "d2uN3l_4zBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Model has been trained and its weights are stored in pothole-detection-learned-weights,\n",
        "if you want to train it yourself uncomment the below code, it takes around 50 minutes.\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"loss_history={\"training_loss\":[],\n",
        "              \"validation_loss\":[]}\n",
        "\n",
        "train_len=len(train_dl.dataset)\n",
        "val_len=len(val_dl.dataset)\n",
        "\n",
        "best_validation_loss=np.inf\n",
        "best_weights=copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    training_loss=0.0\n",
        "    validation_loss=0.0\n",
        "\n",
        "    current_lr=get_lr(optimizer)\n",
        "\n",
        "    #During training, the model expects both the input tensors, as well as a targets\n",
        "    model.train()\n",
        "    for imgs,targets in train_dl:\n",
        "        imgs=[img.to(device) for img in imgs]\n",
        "        targets=[{k:v.to(device) for (k,v) in d.items()} for d in targets]\n",
        "\n",
        "        loss_dict=model(imgs,targets)\n",
        "        losses=sum(loss for loss in loss_dict.values())\n",
        "        training_loss+=losses.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs,targets in val_dl:\n",
        "            imgs=[img.to(device) for img in imgs]\n",
        "            targets=[{k:v.to(device) for (k,v) in d.items()} for d in targets]\n",
        "\n",
        "            loss_dict=model(imgs,targets)\n",
        "            losses=sum(loss for loss in loss_dict.values())\n",
        "            validation_loss+=losses.item()\n",
        "\n",
        "\n",
        "    lr_scheduler.step(validation_loss)\n",
        "    if current_lr!=get_lr(optimizer):\n",
        "        print(\"Loading best Model weights\")\n",
        "        model.load_state_dict(best_weights)\n",
        "\n",
        "    if validation_loss<best_validation_loss:\n",
        "        best_validation_loss=validation_loss\n",
        "        best_weights=copy.deepcopy(model.state_dict())\n",
        "        print(\"Updating Best Model weights\")\n",
        "\n",
        "\n",
        "    loss_history[\"training_loss\"].append(training_loss/train_len)\n",
        "    loss_history[\"validation_loss\"].append(validation_loss/val_len)\n",
        "\n",
        "    print(f\"\\n{epoch+1}/{epochs}\")\n",
        "    print(f\"Training Loss: {training_loss/train_len}\")\n",
        "    print(f\"Validation_loss: {validation_loss/val_len}\")\n",
        "    print(\"\\n\"+\"*\"*50)\n",
        "\n",
        "torch.save(best_weights,model_weights_file)\"\"\""
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-09-01T05:01:57.386654Z",
          "iopub.execute_input": "2023-09-01T05:01:57.387188Z",
          "iopub.status.idle": "2023-09-01T05:01:57.401068Z",
          "shell.execute_reply.started": "2023-09-01T05:01:57.387155Z",
          "shell.execute_reply": "2023-09-01T05:01:57.400106Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "3--6SykPzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"sns.lineplot(x=range(epochs),y=loss_history[\"training_loss\"],label=\"Train Losses\");\n",
        "sns.lineplot(x=range(epochs),y=loss_history[\"validation_loss\"],label=\"Validation Losses\");\n",
        "plt.title(\"Training Validation Datasets Losses Plot\");\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:01:57.40413Z",
          "iopub.execute_input": "2023-09-01T05:01:57.404412Z",
          "iopub.status.idle": "2023-09-01T05:01:57.416182Z",
          "shell.execute_reply.started": "2023-09-01T05:01:57.404389Z",
          "shell.execute_reply": "2023-09-01T05:01:57.415116Z"
        },
        "_kg_hide-output": true,
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "PzRaCCCGzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "yydoGY-IzBo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_weights_pth=\"/kaggle/input/pothole-detection-learned-weights/model.pth\"\n",
        "model=ssd300_vgg16()\n",
        "\n",
        "in_channels=det_utils.retrieve_out_channels(model.backbone,(480,480))\n",
        "num_anchors=model.anchor_generator.num_anchors_per_location()\n",
        "model.head=SSDHead(in_channels=in_channels,num_anchors=num_anchors,\n",
        "                   num_classes=num_classes)\n",
        "\n",
        "model.load_state_dict(torch.load(model_weights_pth,map_location=device))\n",
        "model.to(device)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-09-01T05:19:59.768038Z",
          "iopub.execute_input": "2023-09-01T05:19:59.7684Z",
          "iopub.status.idle": "2023-09-01T05:20:35.858195Z",
          "shell.execute_reply.started": "2023-09-01T05:19:59.768368Z",
          "shell.execute_reply": "2023-09-01T05:20:35.857037Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "ELkXwmRKzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_bbox(prediction):\n",
        "\n",
        "    \"\"\"Non-max suppression is the final step of these object detection algorithms and is\n",
        "       used to select the most appropriate bounding box for the object.\n",
        "       The NMS takes two things into account\n",
        "        -The objectiveness score is given by the model\n",
        "        -The overlap or IOU of the bounding boxes\"\"\"\n",
        "\n",
        "    processed_bbox={}\n",
        "\n",
        "    boxes=prediction[\"boxes\"][prediction[\"scores\"]>=threshold]\n",
        "    scores=prediction[\"scores\"][prediction[\"scores\"]>=threshold]\n",
        "    labels=prediction[\"labels\"][prediction[\"scores\"]>=threshold]\n",
        "    nms=torchvision.ops.nms(boxes,scores,iou_threshold=iou_threshold)\n",
        "\n",
        "    processed_bbox[\"boxes\"]=boxes[nms]\n",
        "    processed_bbox[\"scores\"]=scores[nms]\n",
        "    processed_bbox[\"labels\"]=labels[nms]\n",
        "\n",
        "    return processed_bbox"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:20:35.860114Z",
          "iopub.execute_input": "2023-09-01T05:20:35.861737Z",
          "iopub.status.idle": "2023-09-01T05:20:35.869095Z",
          "shell.execute_reply.started": "2023-09-01T05:20:35.86169Z",
          "shell.execute_reply": "2023-09-01T05:20:35.868105Z"
        },
        "trusted": true,
        "id": "DnfV7nfVzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric=MeanAveragePrecision(box_format='xyxy',class_metrics=True)\n",
        "metric.to(device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for imgs,targets in val_dl:\n",
        "        imgs=[img.to(device) for img in imgs]\n",
        "        targets=[{k:v.to(device) for (k,v) in d.items()} for d in targets]\n",
        "        predictions=model(imgs)\n",
        "\n",
        "        results=[]\n",
        "        for prediction in predictions:\n",
        "            results.append(preprocess_bbox(prediction))\n",
        "\n",
        "        metric.update(results,targets)\n",
        "\n",
        "results=metric.compute()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:20:35.870256Z",
          "iopub.execute_input": "2023-09-01T05:20:35.871269Z",
          "iopub.status.idle": "2023-09-01T05:20:43.15821Z",
          "shell.execute_reply.started": "2023-09-01T05:20:35.871222Z",
          "shell.execute_reply": "2023-09-01T05:20:43.157011Z"
        },
        "trusted": true,
        "id": "Ky34FgGQzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_ap=results[\"map\"].item()\n",
        "mean_ap_50=results[\"map_50\"].item()\n",
        "mean_ap_75=results[\"map_75\"].item()\n",
        "\n",
        "print(f\"Mean Average Precision[0.5:0.95:0.05] : {mean_ap:.4f}\")\n",
        "print(f\"Mean Average Precision @ 0.5          : {mean_ap_50:.4f}\")\n",
        "print(f\"Mean Average Precision @ 0.75         : {mean_ap_75:.4f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:20:43.160704Z",
          "iopub.execute_input": "2023-09-01T05:20:43.161004Z",
          "iopub.status.idle": "2023-09-01T05:20:43.17012Z",
          "shell.execute_reply.started": "2023-09-01T05:20:43.160975Z",
          "shell.execute_reply": "2023-09-01T05:20:43.168499Z"
        },
        "trusted": true,
        "id": "KQku0RgXzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "74-J-tS-zBo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"During inference, the model requires only the input tensors, and returns the\n",
        "   post-processed predictions as a List[Dict[Tensor]], one for each input image. The fields\n",
        "   of the Dict are as follows:\n",
        "   - boxes (FloatTensor[N, 4]): the predicted boxes in [x0, y0, x1, y1] format\n",
        "   - labels (Int64Tensor[N]): the predicted labels for each image\n",
        "   - scores (Tensor[N]): the scores or each prediction\"\"\"\n",
        "\n",
        "fig,axes=plt.subplots(4,2,figsize=(8,16))\n",
        "plt.subplots_adjust(wspace=0.1,hspace=0.1)\n",
        "\n",
        "imgs,targets=next(iter(val_dl))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output=model([img.to(device) for img in imgs])\n",
        "\n",
        "for i,idx in enumerate(range(len(imgs))):\n",
        "    img=imgs[idx]\n",
        "    prediction=output[idx]\n",
        "\n",
        "    #real bounding boxes\n",
        "    output_img=show_bbox(img,targets[idx],color=(0,255,0));\n",
        "    axes[i,0].imshow(output_img);\n",
        "    axes[i,0].axis(\"off\");\n",
        "\n",
        "    #predicted bounding box\n",
        "    predict=preprocess_bbox(prediction)\n",
        "    output_img=show_bbox(img,predict,color=(255,0,0));\n",
        "    axes[i,1].imshow(output_img);\n",
        "    axes[i,1].axis(\"off\");\n",
        "\n",
        "plt.savefig(\"4.png\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:20:48.849407Z",
          "iopub.execute_input": "2023-09-01T05:20:48.850117Z",
          "iopub.status.idle": "2023-09-01T05:20:50.722398Z",
          "shell.execute_reply.started": "2023-09-01T05:20:48.85008Z",
          "shell.execute_reply": "2023-09-01T05:20:50.721485Z"
        },
        "trusted": true,
        "id": "9OYGOAibzBo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Inference"
      ],
      "metadata": {
        "id": "XfEM5fMBzBpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_path=\"/kaggle/input/potholes-detection-inference-on-videos/pothole.mp4\"\n",
        "video_out_path=\"/kaggle/working/output_video.mp4\"\n",
        "\n",
        "cap=cv2.VideoCapture(video_path)\n",
        "if (cap.isOpened() == False):\n",
        "    print('Error while trying to read video. Please check path again')\n",
        "\n",
        "# define codec and create VideoWriter object\n",
        "out=cv2.VideoWriter(video_out_path,\n",
        "                    cv2.VideoWriter_fourcc(*'XVID'), 30,\n",
        "                    (480,480))\n",
        "\n",
        "model=model.eval()\n",
        "\n",
        "# read until end of video\n",
        "while(cap.isOpened()):\n",
        "    # capture each frame of the video\n",
        "    ret, frame=cap.read()\n",
        "    if ret==True:\n",
        "        with torch.no_grad():\n",
        "            # get predictions for the current frame\n",
        "            frame=cv2.resize(frame,(480,480))\n",
        "            frame=frame/255\n",
        "            frame=np.transpose(frame,(2,0,1))\n",
        "            frame=torch.as_tensor(frame,dtype=torch.float32)\n",
        "            frame=frame.to(device)\n",
        "            output=model([frame])\n",
        "            predict=preprocess_bbox(output[0])\n",
        "            output_img=show_bbox(frame,predict)\n",
        "            output_img=(output_img*255).astype(np.uint8)\n",
        "            out.write(output_img)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# release VideoCapture()\n",
        "out.release()\n",
        "cap.release()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T05:21:09.065174Z",
          "iopub.execute_input": "2023-09-01T05:21:09.065698Z",
          "iopub.status.idle": "2023-09-01T05:21:24.60513Z",
          "shell.execute_reply.started": "2023-09-01T05:21:09.06566Z",
          "shell.execute_reply": "2023-09-01T05:21:24.603999Z"
        },
        "trusted": true,
        "id": "pOEDwWdHzBpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real Time Pothole Detection Video\n",
        "Trained Single Shot Detector is used for real time pothole detection on roads. **https://youtube.com/shorts/O8htKfKOyiA**"
      ],
      "metadata": {
        "id": "ziBYc20TzBpF"
      }
    }
  ]
}